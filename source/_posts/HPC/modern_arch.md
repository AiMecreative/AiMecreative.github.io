---
title: HPC | Modern Architecture-Cache
author: Andrew-Rey
date: 2024-04-23 21:01:02
category: HPC
tag: HPC
mathjax: true
---

Parallel Programming: Concepts and Pracitce - Chapter 3

<!--more-->

von Neumann bottleneck: 现代微处理器能够以远高于从主存（DRAM）中读取数据的速率处理数据。
导致的结果是，很多程序受限于访存，而非计算。当然，现在也有很多访存友好的算法，
例如 BLAS 库中的 [GEMM](https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html)

## 缓存算法

缓存算法主要解决以下问题：

- 我们需要从主存装载哪些数据，储存在何处
- 缓存已满时，我们需要移出哪些数据

缓存算法的目的在于优化其 **命中率（cache hit）**。算法遵循以下两条原则：

- **空间局部性**：许多算法会从连续的内存位置访问数据，有较高的空间局部性。例如如下程序：

```cpp
for (int i = 0; i < size; i += 1) {
    max_value = max(a[i], max_value);
}
```

起始缓存为空，访问 `a[0]` 时缓存未命中，需要载入数据，缓存一般一次载入一个完整的 **cache line**。
假设 cache line 大小是64B，数组的值是双精度浮点数，则连续的8个值 `a[0:8]` 会一起被载入缓存，
`a[1:8]` 的数据全部缓存命中。

- **时间局部性**：缓存被组织为一定数目的块，即 cache line。每个块有固定的大小。缓存映射策略可以决定主存的一个特定条目的备份在缓存中的存储位置。
  - **直接映射缓存 direct-mapping cache**：主存每个特定条目在缓存中有唯一的存储位置。命中率较低。
  - **2路组相联缓存 two-way set associative cache**：从主存载入的数据可以存储在2个可能的块中，具体存储的位置由 **最近最少使用（least-recently used, LRU）** 原则决定，往往会选择最近时间最少使用的那个块用来存储主存载入的数据。命中率高于直接映射。常用的还有4路、8路等。

## 缓存一致性

假设需要修改缓存中的值，则不仅需要修改缓存中的值，还需要修改主存中的值，不然会产生不一致（inconsistency），
有两种策略去保证缓存和主存中的一致性（coherence）：

- **直写式**：如果主存中的数据已经缓存，则主存数据发生变动的同时也要修改缓存的值。缺点每次写主存需要一次主存访问
- **回写式**：缓存的值修改时，不会立马修改主存的值，而是会被标记为 `dirty`，待数据移出缓存时，才写入主存

多级缓存和多核处理器的情况会非常复杂，例如每个处理器有自己的本地缓存L1，同时所有的处理器又共享一个公共缓存L2，每个处理器修改L1时，如果没有约束条件，可能会导致其它处理器缓存的值与修改后不一致，L1的值与L2的值也不一样。

一种方式是对于缓存且被修改的值，让其它处理器标记该数据的缓存行为失效，除非重新从主存中载入数据。常用的协议有MESI协议。

**虚假共享**：缓存一致性协议是对于 cache line 而言的，每一行能存多个值，如果修改了某个值，其所在的 cache line 以及其所关联的 cache line （其它核心的 cache line）将会整体失效。一个极端情况是，多个处理器同时修改一个缓存行的不同数据，任意一个写操作都会使缓存行失效，所有处理器都需要从共享主存重新载入数据，即使数据并没有改变。这种情况就是 **虚假共存**。

对于程序员的准则：

- **避免对存储在同一个缓存行中的条目进行过度更新**
- **尽量在寄存器而不是在缓存中存储中间结果**